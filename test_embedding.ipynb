{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "import torchcde\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter('/work/hmzhao/embedding/img')\n",
    "\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y:  torch.Size([100000, 5])\n",
      "normalized X mean: -1.1743464469848672\n",
      "X std: 1.046597228312195\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/work/hmzhao/irregular-lc/KMT-fixrho-test.h5', mode='r') as dataset_file:\n",
    "    Y = torch.tensor(dataset_file['Y'][...])\n",
    "    X = torch.tensor(dataset_file['X'][...])\n",
    "\n",
    "# filter nan\n",
    "nanind = torch.where(~torch.isnan(X[:, 0, 1]))[0]\n",
    "Y = Y[nanind]\n",
    "X = X[nanind]\n",
    "nanind = torch.where(Y[:, 2]>0)[0]\n",
    "Y = Y[nanind]\n",
    "X = X[nanind]\n",
    "nanind = torch.where(Y[:, 2]<1)[0]\n",
    "Y = Y[nanind]\n",
    "X = X[nanind]\n",
    "\n",
    "Y[:, 3:6] = torch.log10(Y[:, 3:6])\n",
    "Y[:, -1] = torch.log10(Y[:, -1])\n",
    "Y[:, 6] = Y[:, 6] / 180\n",
    "# Y = Y[:, 2:]\n",
    "Y = Y[:, [2, 4, 5, 6, 7]]\n",
    "print('Shape of Y: ', Y.shape)\n",
    "\n",
    "X[:, :, 1] = (X[:, :, 1] - 14.5 - 2.5 * Y[:, [-1]]) / 0.2\n",
    "print(f'normalized X mean: {torch.mean(X[:, :, 1])}\\nX std: {torch.mean(torch.std(X[:, :, 1], axis=0))}')\n",
    "\n",
    "X = X[:, :, :2]\n",
    "    \n",
    "# CDE interpolation with log_sig\n",
    "depth = 3; window_length = 5\n",
    "logsig = torchcde.logsig_windows(X, depth, window_length=window_length)\n",
    "coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(logsig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CDE_MDN(\n",
       "  (cde_func): CDEFunc(\n",
       "    (linear1): Linear(in_features=32, out_features=1024, bias=True)\n",
       "    (relu1): PReLU(num_parameters=1)\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (nonlinear1): PReLU(num_parameters=1)\n",
       "        (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (nonlinear1): PReLU(num_parameters=1)\n",
       "        (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (nonlinear1): PReLU(num_parameters=1)\n",
       "        (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (relu2): PReLU(num_parameters=1)\n",
       "    (linear2): Linear(in_features=1024, out_features=160, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (linear3): Linear(in_features=160, out_features=160, bias=True)\n",
       "  )\n",
       "  (initial): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=5, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (nonlinear1): ReLU()\n",
       "      (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (nonlinear1): ReLU()\n",
       "      (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (nonlinear1): ReLU()\n",
       "      (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (readout): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (nonlinear1): ReLU()\n",
       "      (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (nonlinear1): ReLU()\n",
       "      (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (nonlinear1): ReLU()\n",
       "      (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (mdn): MixtureDensityNetwork(\n",
       "    (pi_network): CategoricalNetwork(\n",
       "      (network): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Linear(in_features=1024, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (normal_network): MixtureDiagNormalNetwork(\n",
       "      (network): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Linear(in_features=1024, out_features=120, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.cde_mdn import CDE_MDN\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpt = torch.load('/work/hmzhao/experiments/cde_mdn/experiment_l32nG12diag.ckpt', map_location='cpu')\n",
    "ckpt_args = checkpt['args']\n",
    "state_dict = checkpt['state_dict']\n",
    "\n",
    "output_dim = Y.shape[-1]\n",
    "input_dim = logsig.shape[-1]\n",
    "latent_dim = ckpt_args.latents\n",
    "\n",
    "model = CDE_MDN(input_dim, latent_dim, output_dim).to(device)\n",
    "# model = CDE_MDN(input_dim, latent_dim, output_dim, 32).to(device)\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# 1. filter out unnecessary keys\n",
    "state_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(state_dict) \n",
    "# 3. load the new state dict\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1df13c89d0440c1ae99af5ca26b1a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = 4096 * 4\n",
    "batchsize = 4096\n",
    "n_gaussian = model.n_gaussian\n",
    "latent_dim = model.latent_dim\n",
    "features = torch.zeros((num, latent_dim))\n",
    "model.eval()\n",
    "model.output_feature = True\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(int(np.ceil(num / batchsize)))):\n",
    "        batch = coeffs[i*batchsize:min(i*batchsize+batchsize, num)].float().to(device)\n",
    "        features[i*batchsize:min(i*batchsize+batchsize, num)] = model(batch).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ecefc88dab4819b22f49d789632f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16384 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs = np.zeros((num, 40, 40, 4))\n",
    "for i in tqdm(range(num)):\n",
    "    io_buf = io.BytesIO()\n",
    "    fig, ax = plt.subplots(figsize=(4, 4), dpi=10)\n",
    "    ax.axis('off')\n",
    "    plt.xlim(-2, 2)\n",
    "    ax.scatter(X[i, :, 0], X[i, :, 1], color='black')\n",
    "    fig.savefig(io_buf, format='rgba', dpi=10)\n",
    "    io_buf.seek(0)\n",
    "    imgs[i] = np.reshape(np.frombuffer(io_buf.getvalue(), dtype=np.uint8),\n",
    "                        newshape=(int(fig.bbox.bounds[3]), int(fig.bbox.bounds[2]), -1))\n",
    "    io_buf.close()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "writer.add_embedding(features,\n",
    "                     metadata=Y[:16384, 0].numpy(),\n",
    "                     label_img=imgs[:, :, :, :-1].transpose(0, 3, 1, 2),)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/work/hmzhao/imgs.npy', imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f54a0b84e80>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs[0, :, :, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8, random_state=0, max_iter=int(1e8)).fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 4, ..., 2, 3, 7], dtype=int32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('/work/hmzhao/embedding/kmeans')\n",
    "writer.add_embedding(features,\n",
    "                     metadata=kmeans.labels_,\n",
    "                     label_img=imgs[:, :, :, :-1].transpose(0, 3, 1, 2),)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "274e8ed069bc503cc01fa1aa16068ccb03180744fbf761618fb0dbde6179c71c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ode-rnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
