{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "import torchcde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y:  torch.Size([100000, 6])\n",
      "normalized X mean: -1.1794236895673196\n",
      "X std: 1.0507553336706146\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/work/hmzhao/irregular-lc/KMT-test.h5', mode='r') as dataset_file:\n",
    "    Y = torch.tensor(dataset_file['Y'][...])\n",
    "    X = torch.tensor(dataset_file['X'][...])\n",
    "\n",
    "# filter nan\n",
    "nanind = torch.where(~torch.isnan(X[:, 0, 1]))[0]\n",
    "Y = Y[nanind]\n",
    "X = X[nanind]\n",
    "\n",
    "Y[:, 3:6] = torch.log10(Y[:, 3:6])\n",
    "Y[:, -1] = torch.log10(Y[:, -1])\n",
    "Y[:, 6] = Y[:, 6] / 180\n",
    "Y = Y[:, 2:]\n",
    "print('Shape of Y: ', Y.shape)\n",
    "\n",
    "X[:, :, 1] = (X[:, :, 1] - 14.5 - 2.5 * Y[:, [-1]]) / 0.2\n",
    "print(f'normalized X mean: {torch.mean(X[:, :, 1])}\\nX std: {torch.mean(torch.std(X[:, :, 1], axis=0))}')\n",
    "\n",
    "X = X[:, :, :2]\n",
    "    \n",
    "# CDE interpolation with log_sig\n",
    "depth = 3; window_length = 5\n",
    "logsig = torchcde.logsig_windows(X, depth, window_length=window_length)\n",
    "coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(logsig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CDE_MDN(\n",
       "  (cde_func): CDEFunc(\n",
       "    (linear1): Linear(in_features=32, out_features=1024, bias=True)\n",
       "    (relu1): PReLU(num_parameters=1)\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (nonlinear1): PReLU(num_parameters=1)\n",
       "        (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (nonlinear1): PReLU(num_parameters=1)\n",
       "        (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (nonlinear1): PReLU(num_parameters=1)\n",
       "        (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (relu2): PReLU(num_parameters=1)\n",
       "    (linear2): Linear(in_features=1024, out_features=160, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (linear3): Linear(in_features=160, out_features=160, bias=True)\n",
       "  )\n",
       "  (initial): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=5, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (nonlinear1): ReLU()\n",
       "      (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (nonlinear1): ReLU()\n",
       "      (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (nonlinear1): ReLU()\n",
       "      (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (readout): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (nonlinear1): ReLU()\n",
       "      (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (nonlinear1): ReLU()\n",
       "      (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (nonlinear1): ReLU()\n",
       "      (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (mdn): MixtureDensityNetwork(\n",
       "    (pi_network): CategoricalNetwork(\n",
       "      (network): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Linear(in_features=1024, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (normal_network): MixtureDiagNormalNetwork(\n",
       "      (network): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "        (2): Linear(in_features=1024, out_features=144, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.cde_mdn import CDE_MDN\n",
    "\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpt = torch.load('/work/hmzhao/experiments/cde_mdn/experiment_2.ckpt', map_location='cpu')\n",
    "ckpt_args = checkpt['args']\n",
    "state_dict = checkpt['state_dict']\n",
    "\n",
    "output_dim = Y.shape[-1]\n",
    "input_dim = logsig.shape[-1]\n",
    "latent_dim = ckpt_args.latents\n",
    "\n",
    "model = CDE_MDN(input_dim, latent_dim, output_dim).to(device)\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# 1. filter out unnecessary keys\n",
    "state_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(state_dict) \n",
    "# 3. load the new state dict\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88428d9593b34455abfdced3c1070035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = 64\n",
    "batchsize = 64\n",
    "n_gaussian = model.n_gaussian\n",
    "pis = torch.zeros((num, n_gaussian))\n",
    "locs = torch.zeros((num, n_gaussian, output_dim))\n",
    "scales = torch.zeros((num, n_gaussian, output_dim))\n",
    "model.eval()\n",
    "for i in tqdm(range(int(np.ceil(num / batchsize)))):\n",
    "    batch = coeffs[i*batchsize:min(i*batchsize+batchsize, num)].float().to(device)\n",
    "    pi, normal = model(batch)\n",
    "    pis[i*batchsize:min(i*batchsize+batchsize, num)] = pi.probs.detach().cpu()\n",
    "    locs[i*batchsize:min(i*batchsize+batchsize, num)] = normal.loc.detach().cpu()\n",
    "    scales[i*batchsize:min(i*batchsize+batchsize, num)] = normal.scale.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loglik(pi, loc, scale, x, margin_dim=0):\n",
    "    shape = x.shape\n",
    "    loc = loc[..., margin_dim]\n",
    "    scale = scale[..., margin_dim]\n",
    "    normal = torch.distributions.Normal(loc, scale)\n",
    "    x = x.reshape(-1, loc.shape[0], 1).tile(1, loc.shape[-1])\n",
    "    loglik = normal.log_prob(x)\n",
    "    loglik = torch.logsumexp(torch.log(pi) + loglik.reshape(*shape[:-1], -1), dim=-1)\n",
    "    return loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.7389,  3.0622,  1.6765, -3.8478,  0.0570,  2.5653,  1.7221,  0.5417,\n",
       "         2.6898,  1.8611,  3.4739,  2.7158,  3.2831,  3.1110,  2.1624,  2.4398,\n",
       "         2.6077,  3.8009,  2.5549,  1.8971,  3.7260,  1.2702,  3.5417,  2.7005,\n",
       "         1.2535,  1.6186,  0.9251,  1.5361,  3.6633,  2.6913,  2.3839,  2.9194,\n",
       "         2.7493,  1.0587,  2.3896,  1.5664,  3.6589,  3.6447,  3.1928,  1.8824,\n",
       "         3.3301,  0.8572,  2.3572,  3.2956,  2.9630,  1.6739,  3.2120,  3.3743,\n",
       "         2.9717,  2.1406,  2.0351,  2.2882,  0.4632,  3.5851,  2.7422,  1.8300,\n",
       "         2.6229,  3.5139,  2.4158,  2.1292,  2.7514,  2.3782,  2.8981,  2.0688],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 7\n",
    "get_loglik(pis, locs, scales, Y[:num, [3]], margin_dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "274e8ed069bc503cc01fa1aa16068ccb03180744fbf761618fb0dbde6179c71c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ode-rnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
